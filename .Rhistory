data = training_data,
act.fct = ACTIVATION_FUNCTION,
linear.output = TRUE,
err.fct = "sse",
learningrate = LEARNING_RATE)
# testing_data_actual_rate = data.frame(testing_data)
predict_result = predict(model, testing_data)
View(predict_result)
# Evaluating the model
actual = data.frame(testing_data)
predicted = predict_result
# Evaluation for the AR order number
print("------------------------------------------")
print(paste("Evaluation for the AR Order:", index))
# Calculating the Mean Absolute Error
mae = round(mae(actual$Rate_Original, predicted) * 100, digits = 4)
print(paste("Mean Absolute Error: ", mae, " %", sep = ""))
# Calculating the Root Mean Squared Error
rmse = round(rmse(actual$Rate_Original, predicted) * 100, digits = 4)
print(paste("Root Mean Squared Error: ", rmse, " %", sep = ""))
# Calculating the Mean Absolute Percentage Error Loss
mape = round(MAPE(actual$Rate_Original, predicted) * 100, digits = 4)
print(paste("Mean Absolute Percentage Error Loss: ", mape, " %", sep = ""))
}
# Reading the data-set "vehicles.xlsx"
df = read_excel("./ExchangeUSD.xlsx")
View(df)
# Checking for null values present from the dataset
print(sum(is.na(df)))
# Checking for the summary of the data
print(summary(df))
# Dropping unwanted columns
df = subset(df, select = -c(Wdy, `YYYY/MM/DD`))
df$Rate = df$`USD/EUR`
df_copy = df
# Renaming the Columns of the Data-frame
df = setNames(df, c("Rate_Original", "Rate_Lag"))
View(df)
# Variables used for 1 hidden and 2 hidden layers for the neural network
# NOTE: One of the two sets have to be commented while the other set is used for the model training
# # THIS SET OF VARIABLES IS USED FOR 1 HIDDEN LAYER MLP
HIDDEN_LAYERS = c(6)
ACTIVATION_FUNCTION = "logistic"
LEARNING_RATE = 0.1
# Using the saved dataframe copy
df = df_copy
# Renaming the Columns of the Data-frame
df = setNames(df, c("Rate_Original", "Rate_Lag"))
# Shifting the Rate_Lag column rows by one down below
df['Rate_Lag'] <- c(NA, head(df['Rate_Lag'], dim(df)[1] - 1)[[1]])
# Removing the first row from the dataframe because there is a null value present in the Rate_Lag column
df = drop_na(df)
# normalization
normalize = function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}
# normalized data
df.normalized = data.frame(lapply(df, normalize))
View(df.normalized)
# Creating the Training Data
training_data = df.normalized[1:400,]
# Creating the Testing Data
testing_data = df.normalized[401:500-1,]
View(testing_data)
# Training a model on the data
set.seed(101)
# Training the model
model <- neuralnet(Rate_Original~Rate_Lag,
hidden = HIDDEN_LAYERS,
data = training_data,
act.fct = ACTIVATION_FUNCTION,
linear.output = TRUE,
err.fct = "sse",
learningrate = LEARNING_RATE)
# Plotting the model network structure
plot(model)
# testing_data_actual_rate = data.frame(testing_data)
predict_result = predict(model, testing_data)
# Adding the index column
testing_data$Index = seq.int(nrow(testing_data))
plot(testing_data$Index,testing_data$Rate_Original,
main = "Actual VS Predicted", xlab = "Index",
ylab = "Rate", col = "black", type = "l")
lines(testing_data$Index, predict_result, col="red")
legend("bottomright",                    # Add legend to plot
legend = c("ACTUAL", "PREDICTED"),
col = 1:2,
lty = 1,
cex = 0.50)
predicted_desired_output = data.frame(testing_data$Rate_Original, predicted)
predicted_desired_output = setNames(predicted_desired_output, c("Desired_Output", "Predicted_Output"))
View(predicted_desired_output)
predicted_desired_output = data.frame(testing_data$Rate_Original, predicted)
predicted_desired_output = setNames(predicted_desired_output, c("Desired_Output", "Predicted_Output"))
# Displaying the predicted and the desired output
predicted_desired_output = data.frame(testing_data$Rate_Original, predicted)
# Using the saved dataframe copy
df = df_copy
# Renaming the Columns of the Data-frame
df = setNames(df, c("Rate_Original", "Rate_Lag"))
# Shifting the Rate_Lag column rows by one down below
df['Rate_Lag'] <- c(NA, head(df['Rate_Lag'], dim(df)[1] - 1)[[1]])
# Removing the first row from the dataframe because there is a null value present in the Rate_Lag column
df = drop_na(df)
# normalization
normalize = function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}
# normalized data
df.normalized = data.frame(lapply(df, normalize))
View(df.normalized)
# Creating the Training Data
training_data = df.normalized[1:400,]
# Creating the Testing Data
testing_data = df.normalized[401:500-1,]
View(testing_data)
# Training a model on the data
set.seed(101)
# Training the model
model <- neuralnet(Rate_Original~Rate_Lag,
hidden = HIDDEN_LAYERS,
data = training_data,
act.fct = ACTIVATION_FUNCTION,
linear.output = TRUE,
err.fct = "sse",
learningrate = LEARNING_RATE)
# Plotting the model network structure
plot(model)
# testing_data_actual_rate = data.frame(testing_data)
predict_result = predict(model, testing_data)
# Adding the index column
testing_data$Index = seq.int(nrow(testing_data))
# Plotting the graph
plot(testing_data$Index,testing_data$Rate_Original,
main = "Actual VS Predicted", xlab = "Index",
ylab = "Rate", col = "black", type = "l")
lines(testing_data$Index, predict_result, col="red")
legend("bottomright",                    # Add legend to plot
legend = c("ACTUAL", "PREDICTED"),
col = 1:2,
lty = 1,
cex = 0.50)
# Evaluating the model
actual = data.frame(testing_data)
predicted = predict_result
predicted_desired_output = data.frame(testing_data$Rate_Original, predicted)
predicted_desired_output = setNames(predicted_desired_output, c("Desired_Output", "Predicted_Output"))
View(predicted_desired_output)
df = df_copy
# Renaming the Columns of the Data-frame
df = setNames(df, c("Rate_Original", "Rate_Lag"))
# Shifting the Rate_Lag column rows by one down below
df['Rate_Lag'] <- c(NA, head(df['Rate_Lag'], dim(df)[1] - 1)[[1]])
# Removing the first row from the dataframe because there is a null value present in the Rate_Lag column
df = drop_na(df)
# normalization
normalize = function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}
# normalized data
df.normalized = data.frame(lapply(df, normalize))
View(df.normalized)
# Creating the Training Data
training_data = df.normalized[1:400,]
# Creating the Testing Data
testing_data = df.normalized[401:500-1,]
View(testing_data)
# Training a model on the data
set.seed(101)
# Training the model
model <- neuralnet(Rate_Original~Rate_Lag,
hidden = HIDDEN_LAYERS,
data = training_data,
act.fct = ACTIVATION_FUNCTION,
linear.output = TRUE,
err.fct = "sse",
learningrate = LEARNING_RATE)
# Plotting the model network structure
plot(model)
# testing_data_actual_rate = data.frame(testing_data)
predict_result = predict(model, testing_data)
# Adding the index column
testing_data$Index = seq.int(nrow(testing_data))
# Plotting the graph
plot(testing_data$Index,testing_data$Rate_Original,
main = "Actual VS Predicted", xlab = "Index",
ylab = "Rate", col = "black", type = "l")
lines(testing_data$Index, predict_result, col="red")
legend("bottomright",                    # Add legend to plot
legend = c("ACTUAL", "PREDICTED"),
col = 1:2,
lty = 1,
cex = 0.50)
# Evaluating the model
actual = data.frame(testing_data)
predicted = predict_result
# Displaying the predicted and the desired output
predicted_desired_output = data.frame(testing_data$Rate_Original, predicted)
predicted_desired_output = setNames(predicted_desired_output, c("Desired_Output", "Predicted_Output"))
View(predicted_desired_output)
df = df_copy
# Renaming the Columns of the Data-frame
df = setNames(df, c("Rate_Original", "Rate_Lag"))
# Shifting the Rate_Lag column rows by one down below
df['Rate_Lag'] <- c(NA, head(df['Rate_Lag'], dim(df)[1] - 1)[[1]])
# Removing the first row from the dataframe because there is a null value present in the Rate_Lag column
df = drop_na(df)
# normalization
normalize = function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}
# normalized data
df.normalized = data.frame(lapply(df, normalize))
View(df.normalized)
# Creating the Training Data
training_data = df.normalized[1:400,]
# Creating the Testing Data
testing_data = df.normalized[401:499,]
View(testing_data)
# Training a model on the data
set.seed(101)
# Training the model
model <- neuralnet(Rate_Original~Rate_Lag,
hidden = HIDDEN_LAYERS,
data = training_data,
act.fct = ACTIVATION_FUNCTION,
linear.output = TRUE,
err.fct = "sse",
learningrate = LEARNING_RATE)
# Plotting the model network structure
plot(model)
# testing_data_actual_rate = data.frame(testing_data)
predict_result = predict(model, testing_data)
# Adding the index column
testing_data$Index = seq.int(nrow(testing_data))
# Plotting the graph
plot(testing_data$Index,testing_data$Rate_Original,
main = "Actual VS Predicted", xlab = "Index",
ylab = "Rate", col = "black", type = "l")
lines(testing_data$Index, predict_result, col="red")
legend("bottomright",                    # Add legend to plot
legend = c("ACTUAL", "PREDICTED"),
col = 1:2,
lty = 1,
cex = 0.50)
# Evaluating the model
actual = data.frame(testing_data)
predicted = predict_result
# Displaying the predicted and the desired output
predicted_desired_output = data.frame(testing_data$Rate_Original, predicted)
predicted_desired_output = setNames(predicted_desired_output, c("Desired_Output", "Predicted_Output"))
View(predicted_desired_output)
mae = round(mae(actual$Rate_Original, predicted) * 100, digits = 4)
print(paste("Mean Absolute Error: ", mae, " %", sep = ""))
# Calculating the Root Mean Squared Error
rmse = round(rmse(actual$Rate_Original, predicted) * 100, digits = 4)
print(paste("Root Mean Squared Error: ", rmse, " %", sep = ""))
# Calculating the Mean Absolute Percentage Error Loss
mape = round(MAPE(actual$Rate_Original, predicted) * 100, digits = 4)
print(paste("Mean Absolute Percentage Error Loss: ", mape, " %", sep = ""))
df = read_excel("./ExchangeUSD.xlsx")
View(df)
# Checking for null values present from the dataset
print(sum(is.na(df)))
# Checking for the summary of the data
print(summary(df))
# Dropping unwanted columns
df = subset(df, select = -c(Wdy, `YYYY/MM/DD`))
df$Rate = df$`USD/EUR`
df_copy = df
# Renaming the Columns of the Data-frame
df = setNames(df, c("Rate_Original", "Rate_Lag"))
View(df)
# Variables used for 1 hidden and 2 hidden layers for the neural network
# NOTE: One of the two sets have to be commented while the other set is used for the model training
# # THIS SET OF VARIABLES IS USED FOR 1 HIDDEN LAYER MLP
# HIDDEN_LAYERS = c(6)
# ACTIVATION_FUNCTION = "logistic"
# LEARNING_RATE = 0.1
# THIS SET OF VARIABLES ARE USED FOR THE 2 HIDDEN LAYER MLP
HIDDEN_LAYERS = c(6,6)
ACTIVATION_FUNCTION = "logistic"
LEARNING_RATE = 0.08
# Since AR1 gave the best result we will be using that
# Using the saved dataframe copy
df = df_copy
# Renaming the Columns of the Data-frame
df = setNames(df, c("Rate_Original", "Rate_Lag"))
# Shifting the Rate_Lag column rows by one down below
df['Rate_Lag'] <- c(NA, head(df['Rate_Lag'], dim(df)[1] - 1)[[1]])
# Removing the first row from the dataframe because there is a null value present in the Rate_Lag column
df = drop_na(df)
# normalization
normalize = function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}
# normalized data
df.normalized = data.frame(lapply(df, normalize))
View(df.normalized)
# Creating the Training Data
training_data = df.normalized[1:400,]
# Creating the Testing Data
testing_data = df.normalized[401:499,]
View(testing_data)
# Training a model on the data
set.seed(101)
# Training the model
model <- neuralnet(Rate_Original~Rate_Lag,
hidden = HIDDEN_LAYERS,
data = training_data,
act.fct = ACTIVATION_FUNCTION,
linear.output = TRUE,
err.fct = "sse",
learningrate = LEARNING_RATE)
# Plotting the model network structure
plot(model)
# testing_data_actual_rate = data.frame(testing_data)
predict_result = predict(model, testing_data)
# Adding the index column
testing_data$Index = seq.int(nrow(testing_data))
# Plotting the graph
plot(testing_data$Index,testing_data$Rate_Original,
main = "Actual VS Predicted", xlab = "Index",
ylab = "Rate", col = "black", type = "l")
lines(testing_data$Index, predict_result, col="red")
legend("bottomright",                    # Add legend to plot
legend = c("ACTUAL", "PREDICTED"),
col = 1:2,
lty = 1,
cex = 0.50)
# Evaluating the model
actual = data.frame(testing_data)
predicted = predict_result
# Displaying the predicted and the desired output
predicted_desired_output = data.frame(testing_data$Rate_Original, predicted)
predicted_desired_output = setNames(predicted_desired_output, c("Desired_Output", "Predicted_Output"))
View(predicted_desired_output)
# Calculating the Mean Absolute Error
mae = round(mae(actual$Rate_Original, predicted) * 100, digits = 4)
print(paste("Mean Absolute Error: ", mae, " %", sep = ""))
# Calculating the Root Mean Squared Error
rmse = round(rmse(actual$Rate_Original, predicted) * 100, digits = 4)
print(paste("Root Mean Squared Error: ", rmse, " %", sep = ""))
# Calculating the Mean Absolute Percentage Error Loss
mape = round(MAPE(actual$Rate_Original, predicted) * 100, digits = 4)
print(paste("Mean Absolute Percentage Error Loss: ", mape, " %", sep = ""))
df = read_excel("./ExchangeUSD.xlsx")
View(df)
# Checking for null values present from the dataset
print(sum(is.na(df)))
# Checking for the summary of the data
print(summary(df))
# Dropping unwanted columns
df = subset(df, select = -c(Wdy, `YYYY/MM/DD`))
df$Rate = df$`USD/EUR`
df_copy = df
# Renaming the Columns of the Data-frame
df = setNames(df, c("Rate_Original", "Rate_Lag"))
View(df)
# Variables used for 1 hidden and 2 hidden layers for the neural network
# NOTE: One of the two sets have to be commented while the other set is used for the model training
# # THIS SET OF VARIABLES IS USED FOR 1 HIDDEN LAYER MLP
HIDDEN_LAYERS = c(6)
ACTIVATION_FUNCTION = "logistic"
LEARNING_RATE = 0.1
# Since AR1 gave the best result we will be using that
# Using the saved dataframe copy
df = df_copy
# Renaming the Columns of the Data-frame
df = setNames(df, c("Rate_Original", "Rate_Lag"))
# Shifting the Rate_Lag column rows by one down below
df['Rate_Lag'] <- c(NA, head(df['Rate_Lag'], dim(df)[1] - 1)[[1]])
# Removing the first row from the dataframe because there is a null value present in the Rate_Lag column
df = drop_na(df)
# normalization
normalize = function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}
# normalized data
df.normalized = data.frame(lapply(df, normalize))
View(df.normalized)
# Creating the Training Data
training_data = df.normalized[1:400,]
# Creating the Testing Data
testing_data = df.normalized[401:499,]
View(testing_data)
# Training a model on the data
set.seed(101)
# Training the model
model <- neuralnet(Rate_Original~Rate_Lag,
hidden = HIDDEN_LAYERS,
data = training_data,
act.fct = ACTIVATION_FUNCTION,
linear.output = TRUE,
err.fct = "sse",
learningrate = LEARNING_RATE)
# Plotting the model network structure
plot(model)
# testing_data_actual_rate = data.frame(testing_data)
predict_result = predict(model, testing_data)
# Adding the index column
testing_data$Index = seq.int(nrow(testing_data))
# Plotting the graph
plot(testing_data$Index,testing_data$Rate_Original,
main = "Actual VS Predicted", xlab = "Index",
ylab = "Rate", col = "black", type = "l")
lines(testing_data$Index, predict_result, col="red")
legend("bottomright",                    # Add legend to plot
legend = c("ACTUAL", "PREDICTED"),
col = 1:2,
lty = 1,
cex = 0.50)
# Evaluating the model
actual = data.frame(testing_data)
predicted = predict_result
# Displaying the predicted and the desired output
predicted_desired_output = data.frame(testing_data$Rate_Original, predicted)
predicted_desired_output = setNames(predicted_desired_output, c("Desired_Output", "Predicted_Output"))
View(predicted_desired_output)
# Calculating the Mean Absolute Error
mae = round(mae(actual$Rate_Original, predicted) * 100, digits = 4)
print(paste("Mean Absolute Error: ", mae, " %", sep = ""))
# Calculating the Root Mean Squared Error
rmse = round(rmse(actual$Rate_Original, predicted) * 100, digits = 4)
print(paste("Root Mean Squared Error: ", rmse, " %", sep = ""))
# Calculating the Mean Absolute Percentage Error Loss
mape = round(MAPE(actual$Rate_Original, predicted) * 100, digits = 4)
print(paste("Mean Absolute Percentage Error Loss: ", mape, " %", sep = ""))
df = read_excel("./ExchangeUSD.xlsx")
View(df)
# Checking for null values present from the dataset
print(sum(is.na(df)))
# Checking for the summary of the data
print(summary(df))
# Dropping unwanted columns
df = subset(df, select = -c(Wdy, `YYYY/MM/DD`))
df$Rate = df$`USD/EUR`
df_copy = df
# Renaming the Columns of the Data-frame
df = setNames(df, c("Rate_Original", "Rate_Lag"))
View(df)
# Variables used for 1 hidden and 2 hidden layers for the neural network
# NOTE: One of the two sets have to be commented while the other set is used for the model training
# # THIS SET OF VARIABLES IS USED FOR 1 HIDDEN LAYER MLP
# HIDDEN_LAYERS = c(6)
# ACTIVATION_FUNCTION = "logistic"
# LEARNING_RATE = 0.1
# THIS SET OF VARIABLES ARE USED FOR THE 2 HIDDEN LAYER MLP
HIDDEN_LAYERS = c(6,6)
ACTIVATION_FUNCTION = "logistic"
LEARNING_RATE = 0.08
df = df_copy
# Renaming the Columns of the Data-frame
df = setNames(df, c("Rate_Original", "Rate_Lag"))
# Shifting the Rate_Lag column rows by one down below
df['Rate_Lag'] <- c(NA, head(df['Rate_Lag'], dim(df)[1] - 1)[[1]])
# Removing the first row from the dataframe because there is a null value present in the Rate_Lag column
df = drop_na(df)
# normalization
normalize = function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}
# normalized data
df.normalized = data.frame(lapply(df, normalize))
View(df.normalized)
# Creating the Training Data
training_data = df.normalized[1:400,]
# Creating the Testing Data
testing_data = df.normalized[401:499,]
View(testing_data)
# Training a model on the data
set.seed(101)
# Training the model
model <- neuralnet(Rate_Original~Rate_Lag,
hidden = HIDDEN_LAYERS,
data = training_data,
act.fct = ACTIVATION_FUNCTION,
linear.output = TRUE,
err.fct = "sse",
learningrate = LEARNING_RATE)
# Plotting the model network structure
plot(model)
# testing_data_actual_rate = data.frame(testing_data)
predict_result = predict(model, testing_data)
# Adding the index column
testing_data$Index = seq.int(nrow(testing_data))
# Plotting the graph
plot(testing_data$Index,testing_data$Rate_Original,
main = "Actual VS Predicted", xlab = "Index",
ylab = "Rate", col = "black", type = "l")
lines(testing_data$Index, predict_result, col="red")
legend("bottomright",                    # Add legend to plot
legend = c("ACTUAL", "PREDICTED"),
col = 1:2,
lty = 1,
cex = 0.50)
# Evaluating the model
actual = data.frame(testing_data)
predicted = predict_result
# Displaying the predicted and the desired output
predicted_desired_output = data.frame(testing_data$Rate_Original, predicted)
predicted_desired_output = setNames(predicted_desired_output, c("Desired_Output", "Predicted_Output"))
View(predicted_desired_output)
# Calculating the Mean Absolute Error
mae = round(mae(actual$Rate_Original, predicted) * 100, digits = 4)
print(paste("Mean Absolute Error: ", mae, " %", sep = ""))
# Calculating the Root Mean Squared Error
rmse = round(rmse(actual$Rate_Original, predicted) * 100, digits = 4)
print(paste("Root Mean Squared Error: ", rmse, " %", sep = ""))
# Calculating the Mean Absolute Percentage Error Loss
mape = round(MAPE(actual$Rate_Original, predicted) * 100, digits = 4)
print(paste("Mean Absolute Percentage Error Loss: ", mape, " %", sep = ""))
